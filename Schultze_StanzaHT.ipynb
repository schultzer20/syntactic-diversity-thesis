{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "CPmAl55zyklQ",
    "outputId": "e713d98d-ed6e-4713-e97b-7621c4662034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (2.0.2)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (5.29.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.5)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.14.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
      "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed emoji-2.14.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stanza-1.10.1\n"
     ]
    }
   ],
   "source": [
    "#Python NLP library Stanza\n",
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "x78jqwD2GsUu",
    "outputId": "0aaabeed-606f-43f8-8732-37cce8159d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "iSniO2plicmb",
    "outputId": "fb201e72-414b-4a97-f25a-2f9f6048b3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unbabel-comet\n",
      "  Downloading unbabel_comet-2.2.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting entmax<2.0,>=1.1 (from unbabel-comet)\n",
      "  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.33.1)\n",
      "Collecting jsonargparse==3.13.1 (from unbabel-comet)\n",
      "  Downloading jsonargparse-3.13.1-py3-none-any.whl.metadata (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0.0,>=1.20.0 (from unbabel-comet)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.2.2)\n",
      "Collecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting pytorch-lightning<3.0.0,>=2.0.0 (from unbabel-comet)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (1.15.3)\n",
      "Requirement already satisfied: sentencepiece<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (2.6.0+cu124)\n",
      "Collecting torchmetrics<0.11.0,>=0.10.2 (from unbabel-comet)\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.11/dist-packages (from unbabel-comet) (4.53.0)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.11/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.1->unbabel-comet) (2025.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.11.15)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet) (2025.6.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.20.1)\n",
      "Downloading unbabel_comet-2.2.6-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading entmax-1.3-py3-none-any.whl (13 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: protobuf, numpy, lightning-utilities, jsonargparse, torchmetrics, entmax, pytorch-lightning, unbabel-comet\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed entmax-1.3 jsonargparse-3.13.1 lightning-utilities-0.14.3 numpy-1.26.4 protobuf-4.25.8 pytorch-lightning-2.5.2 torchmetrics-0.10.3 unbabel-comet-2.2.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "380ad86166e645a087ad209c305ab184",
       "pip_warning": {
        "packages": [
         "google",
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400,
     "referenced_widgets": [
      "126bcef55ffc490180b244af8abc45f1",
      "02009876a84648cba5c70ec3f056bc5b",
      "c6a3c6dc2a6d42cbb60e2c4c36ff6fb1",
      "b1a767a1c8ff4794b2fd9b3cd978e8a9",
      "8f0c4b23107840179d6caac253b8037d",
      "efe9ae727a164331b6622a4669ab6082",
      "15ce0ad0573147a8bd9701872f03c565",
      "b10c42d055044621a996438b934b82fd",
      "ac8a6bd1a2d840889982c65f91b6c0f1",
      "72bb82cb8dd74040a321cb01a6b2c85a",
      "9705db8b87484b32beda31996bfd33c7",
      "1e42ae6b0a0147d18d53cc858a2fe74e",
      "23543975fbd944f895efe2cce8d60188",
      "c03f67bce5904b918aee5617ade32db6",
      "9c282ac960554f41863fa7b93261d9eb",
      "67618ef9c38f4fa1b6a6261f4c465aa0",
      "e5646aa6ca804ba99caf93e8d0889416",
      "be6873475040480cb95283b36b2e2967",
      "057ac41aa34d49d68f40b5510019d4e7",
      "2d9758e527e44dfaac8e5ef7a3777850",
      "172fbd216360462d93afc12ec864f5ac",
      "2d1ea1f8df2d4dce92d1d8696dc5e47b",
      "910f3e9ad2a84f8489a31191664bd659",
      "c20afee2766e4b5fae37d829101728dd",
      "2411296aa064485cbc482e4fce0bead7",
      "d758f01121df4cba80d11203e75ddf14",
      "33bfeccf1c3c45b5b73c62c21ee03f29",
      "774372c8b0be4f30961009db4b4bad7a",
      "bcf0a8cfba124eb0bfa35da5caeb5b80",
      "5843445c0cf84e159ddb8e11ed80233f",
      "84c0076243f143b48f548681d84fc0b1",
      "bb4faccbcfa745f188a1721b3c526720",
      "dd3b0bef8064400a8e1124d6068d13d4",
      "cd923a280a534093a0e3799c82f2bb40",
      "253966a470a44d77b483d253e61d3c05",
      "4eb0bc1820ed4969baa459f68352c0c2",
      "cc78c7bc87ca424a961617c1e9986eeb",
      "6581aa5c5d9346649a68db9c06989b6d",
      "c4a4af1fc0534295b57f9f274a2dbc0b",
      "51463d5f8d0543188f9577f0d1b58046",
      "93d359494ab740329854cb356b7d719f",
      "c63fed8451944ef39e46f8fbfc6fe57f",
      "4a8f632e97804cc096462a93924b2aca",
      "cf68f92c9e2d4e19b917f30d022e40d4"
     ]
    },
    "collapsed": true,
    "id": "A-gdfY-kxlDz",
    "outputId": "bf2e49e4-5eeb-4555-95a3-19b85414a330"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126bcef55ffc490180b244af8abc45f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: de (German) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e42ae6b0a0147d18d53cc858a2fe74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.10.0/models/default.zip:   0%|          | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/de/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f3e9ad2a84f8489a31191664bd659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
      "INFO:stanza:Downloading default packages for language: pt (Portuguese) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd923a280a534093a0e3799c82f2bb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-pt/resolve/v1.10.0/models/default.zip:   0%|          | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/pt/default.zip\n",
      "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "#pre-trained NLP models\n",
    "stanza.download('de')\n",
    "stanza.download('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e02dae605c9840ebbd1c25982ec92bfb",
      "639d7a1b91d141b8972f322c843a9fdb",
      "10430aa577a44d9f97e20d048157ed29",
      "ede8ce6eb54e4ab09f43cbe6daa29c1d",
      "fa42049c37354a598bf9c564d3f1986d",
      "4eb69ff9774343eb93cea9cda33caedc",
      "5fb7ca3e558242c3b0955b8383b9b8bf",
      "d042fc7320ba4ee29dc302d14cd72997",
      "2db006d330574517a17600e79d69b4ac",
      "7cb0f812b4154f20b52242da9f5c68fd",
      "fde58a9fbf3343f591ede55632f7d8fe",
      "855f612ed569405b921c11fa04d2372d",
      "bd0a344c62e140bc9ea1727d5334ae5d",
      "362d35fd46694880986cb951a48a19d0",
      "d2d4eeede2124ab39d415c756c331f9a",
      "47cd115e2e5f46f6ad72c868e9812ac9",
      "bed74ef00b5345a0914aacc557b87cdc",
      "78fe8755b4a448ff9f0e40e3116914f1",
      "e7abd7429ad84ed4be4a4011d9ee1403",
      "754cc6e7266949e295dd2d9c37f1a21a",
      "13490d102593415c840d533fb34b30d3",
      "685b8a719e7e4679b9430b85dede3d49"
     ]
    },
    "collapsed": true,
    "id": "NINM0S5gxiyM",
    "outputId": "a15abd89-d77d-473f-90f0-a8597da5b739"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02dae605c9840ebbd1c25982ec92bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
      "INFO:stanza:Loading these models for language: de (German):\n",
      "====================================\n",
      "| Processor    | Package           |\n",
      "------------------------------------\n",
      "| tokenize     | combined          |\n",
      "| mwt          | combined          |\n",
      "| pos          | combined_charlm   |\n",
      "| lemma        | combined_nocharlm |\n",
      "| constituency | spmrl_charlm      |\n",
      "| depparse     | combined_charlm   |\n",
      "| sentiment    | sb10k_charlm      |\n",
      "| ner          | germeval2014      |\n",
      "====================================\n",
      "\n",
      "INFO:stanza:Using device: cpu\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: mwt\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Loading: lemma\n",
      "INFO:stanza:Loading: constituency\n",
      "INFO:stanza:Loading: depparse\n",
      "INFO:stanza:Loading: sentiment\n",
      "INFO:stanza:Loading: ner\n",
      "INFO:stanza:Done loading processors!\n",
      "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855f612ed569405b921c11fa04d2372d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
      "INFO:stanza:Loading these models for language: pt (Portuguese):\n",
      "==================================\n",
      "| Processor    | Package         |\n",
      "----------------------------------\n",
      "| tokenize     | bosque          |\n",
      "| mwt          | bosque          |\n",
      "| pos          | bosque_charlm   |\n",
      "| lemma        | bosque_nocharlm |\n",
      "| constituency | cintil_charlm   |\n",
      "| depparse     | bosque_charlm   |\n",
      "==================================\n",
      "\n",
      "INFO:stanza:Using device: cpu\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: mwt\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Loading: lemma\n",
      "INFO:stanza:Loading: constituency\n",
      "INFO:stanza:Loading: depparse\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#NLP pipelines\n",
    "pipeline_de = stanza.Pipeline(lang='de', processor='tokenize,pos,lemma,depparse,constituency')\n",
    "pipeline_pt = stanza.Pipeline(lang='pt', processor='tokenize,pos,lemma,depparse,constituency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "-woj-LPSy9U-"
   },
   "outputs": [],
   "source": [
    "#doc = pipeline_de('Ich bin seit dem 25. des letzten Monats im Hospiz, oder vielmehr in verschiedenen Teilen davon.')\n",
    "#print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wqsNQ0UFzZ6K"
   },
   "outputs": [],
   "source": [
    "#doc = pipeline_pt('Estou no Hospício ou, melhor, em várias dependências dele, desde o dia 25 do mês passado.')\n",
    "#print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QU3qdOKeD3MZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VadeW2DJ_dT"
   },
   "outputs": [],
   "source": [
    "#ex_text = '''Ich bin seit dem 25. des letzten Monats im Hospiz, oder vielmehr in verschiedenen Teilen davon. Ich war auf der Beobachtungsstation, die die schlimmste Stufe für diejenigen ist, die wie ich hier in die Hände der Polizei geraten.\n",
    "#Sie nehmen dir die Kleidung weg, die du trägst, und geben dir eine andere, die nur deine Blöße bedeckt, und sie geben dir nicht einmal Hausschuhe oder Clogs. Das andere Mal, als ich dort war, haben sie mir dieses Kleidungsstück geschenkt, das jetzt für mich unverzichtbar ist. Diesmal nicht. Die alte Krankenschwester war menschlich und gut; die jetzige ist eine arrogante Portugiesin (die andere war es), mit einer prahlerischen und anmaßenden Physiognomie.\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5Q2vO3-CyS-"
   },
   "source": [
    "# Text and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C89c-ix5OHi"
   },
   "outputs": [],
   "source": [
    "#FULLY ALIGNED Papel moeda\n",
    "\n",
    "ST ='''Gosto muito de aprender finanças, nos artigos de jornais.\n",
    "Não aparece uma discussão dessa matéria que eu a não siga. Agora anda uma dessa natureza que apaixona Câmara, Senado, jornais e povo, sobre o papel-moeda.\n",
    "O senhor presidente da república, vendo as aperturas em que está a Nação, pediu ao congresso autorização para emitir uma grande quantidade dele; ou por outra: fez um deputado amigo apresentar um projeto autorizando isto.\n",
    "Surgiram logo uma porção de críticas, demonstrando que essas emissões constantes de papel-moeda desmoralizam o nosso mercado monetário; que é preciso saneá-lo com ouro ou com papel que se converta em ouro, etc., etc.\n",
    "Nada entendo dessas coisas, mas vou dar o meu humilde parecer.\n",
    "Julgo que essa gente não tem razão, porque ouro é o que ouro vale; e se o papel lhe equivale, em virtude de um decreto do governo, não há motivo para zangas.\n",
    "Além disto, o mesmo governo quer criar um banco emissor e de redesconto, à vista da falta de numerário. Esta falta admira-me muito que só agora a vissem. Eu de há muito que a sinto, e bem profundamente, meus caros senhores.\n",
    "Mas... se há falta de numerário, creio que o que se deve fazer é aumentá-lo.\n",
    "Ouro é coisa rara, mesmo no Brasil, onde dele, segundo dizem, há minas por toda a parte; mas papel é coisa que se encontra logo e, relativamente, é barato.\n",
    "Demais, se o governo aumentar as notas de papel, é de presumir que alguma venha a tocar-nos. E o ouro? Vai logo para o encaixe dos bancos e só o verão os milionários.\n",
    "Se o Estado quer ser sábio e promover a felicidade do povo, deve, quanto antes, aumentar a circulação do papel moeda, não de quinhentos mil contos, mas de tantos milhões quantos forem os habitantes que o sábio doutor Bulhões encontrar, no seu recenseamento, neste vasto Brasil.\n",
    "É de esperar que assim venha tocar uma nota de dez tostões a cada um, enquanto, com o sistema vigente, muitos andam por ai pedindo-a por esmola.\n",
    "Tenho pena de não poder faze-las em casa; porque isto é privilégio do Estado e se eu tal fizesse iria parar na cadeia como moedeiro falso; mas, se assim não fosse, faria uma de cinquenta todo o dia, e, no fim do mês, o necessário para pagar a casa e o vendeiro.\n",
    "Nem todo o mundo tem os direitos do governo...\n",
    "'''\n",
    "\n",
    "MT ='''Ich lerne sehr gerne etwas über Finanzen aus Zeitungsartikeln.\n",
    "Es gibt keine Diskussion zu diesem Thema, die ich nicht verfolge. Derzeit gibt es eine solche Diskussion, die den Kongress, den Senat, die Zeitungen und die Bevölkerung begeistert, nämlich über Papiergeld.\n",
    "Der Präsident der Republik hat angesichts der schwierigen Lage, in der sich die Nation befindet, den Kongress um die Genehmigung zur Ausgabe einer großen Menge davon gebeten; oder anders gesagt: Er hat einen befreundeten Abgeordneten einen Gesetzentwurf vorlegen lassen, der dies genehmigt.\n",
    "Sofort hagelte es Kritik, dass diese ständige Ausgabe von Papiergeld unseren Geldmarkt demoralisiere, dass er mit Gold oder mit Papier, das in Gold umgewandelt werden könne, saniert werden müsse, usw., usw.\n",
    "Ich verstehe nichts von diesen Dingen, aber ich werde meine bescheidene Meinung dazu äußern.\n",
    "Ich halte diese Leute für unrecht, denn Gold ist Gold wert, und wenn Papier aufgrund eines Regierungsdekrets dem Gold gleichwertig ist, gibt es keinen Grund zur Aufregung.\n",
    "Darüber hinaus will dieselbe Regierung angesichts des Geldmangels eine Emissions- und Diskontbank schaffen. Es wundert mich sehr, dass dieser Mangel erst jetzt bemerkt wurde. Ich spüre ihn schon seit langem und sehr deutlich, meine Herren.\n",
    "Aber ... wenn es an Bargeld mangelt, sollte man meiner Meinung nach die Geldmenge erhöhen.\n",
    "Gold ist selbst in Brasilien, wo es angeblich überall Minen gibt, eine Seltenheit, aber Papier ist leicht zu beschaffen und relativ billig.\n",
    "Außerdem ist anzunehmen, dass, wenn die Regierung den Papiergeldumlauf erhöht, etwas davon auch zu uns gelangt. Und das Gold? Das landet sofort in den Kassen der Banken und nur die Millionäre werden es zu Gesicht bekommen.\n",
    "Wenn der Staat klug sein und das Glück des Volkes fördern will, muss er so schnell wie möglich den Papiergeldumlauf erhöhen, nicht um 500 Millionen, sondern um so viele Millionen, wie viele Einwohner der weise Doktor Bulhões bei seiner Volkszählung in diesem riesigen Brasilien findet.\n",
    "Es ist zu hoffen, dass dann jeder einen Zehn-Cent-Schein bekommt, während unter dem derzeitigen System viele um Almosen betteln.\n",
    "Ich bedaure, dass ich sie nicht zu Hause herstellen kann, denn dies ist ein Privileg des Staates, und wenn ich es täte, würde ich als Falschmünzer im Gefängnis landen, aber wenn es nicht so wäre, würde ich jeden Tag einen Fünfzigerschein herstellen und am Ende des Monats hätte ich genug, um die Miete und den Ladenbesitzer zu bezahlen.\n",
    "Nicht jeder hat die Rechte der Regierung...'''\n",
    "\n",
    "HT ='''Es bereitet mir wirklich Freude, aus Zeitungsberichten etwas über Finanzen zu lernen.\n",
    "Nichts erscheint zu diesem Thema, ohne dass ich es verfolgen würde. Die Diskussion, die im Augenblick Abgeordnetenkammer, Senat, Presse und Volk in Atem hält, dreht sich um das Papiergeld.\n",
    "Als der Präsident der Republik erkannte, in welch schwieriger Lage die Nation sich befand, bat er den Kongress um die Befugnis, eine große Menge davon in Umlauf bringen zu dürfen, mit anderen Worten, er ließ einen befreundeten Abgeordneten einen Gesetzesentwurf einbringen, der dies erlaubt.\n",
    "Schon bald wurde Kritik laut, und es wurde behauptet, dass die kontinuierliche Emission von Papiergeld unseren Geldmarkt schwäche; und dass er gerettet werden müsse, mit Gold oder mit Papier, das sich in Gold verwandelt, usw., usw.\n",
    "Ich verstehe nichts von diesen Dingen, aber ich werde dennoch meine bescheidene Meinung kundtun.\n",
    "Meiner Einschätzung nach irren sich diese Menschen, denn Gold ist das, was das Gold wert ist; und wenn Papier aufgrund eines Regierungsdekrets gleich viel wert ist, gibt es keinen Grund, sich zu streiten.\n",
    "Darüber hinaus will die Regierung angesichts des Bargeldmangels eine Emissions- und Rediskontierungsbank schaffen. Was nun diesen Mangel angeht, bin ich sehr überrascht, dass sie ihn erst jetzt sehen. Denn ich verspüre ihn schon lange und sehr heftig, meine geschätzten Herren.\n",
    "Aber ..., wenn es einen Mangel an Bargeld gibt, sollte man es meiner Ansicht nach vermehren.\n",
    "Gold ist etwas Seltenes, sogar in Brasilien, wo es ja angeblich überall Minen gibt, aber Papier ist leicht verfügbar und vergleichsweise billig.\n",
    "Wenn die Regierung die Menge der Banknoten erhöht, können wir zudem annehmen, dass wir ein paar davon zu Gesicht bekommen werden. Und das Gold? Das geht direkt an die Banken und nur die Millionäre sehen es.\n",
    "Wenn der Staat weise sein und das Glück des Volkes fördern will, sollte er schleunigst mehr Banknoten in Umlauf bringen, aber nicht nur fünfhunderttausend, sondern so viele Millionen, wie es in diesem riesigen Brasilien der Volkszählung des gelehrten Doutor Bulhões zufolge Einwohner gibt.\n",
    "Es ist zu hoffen, dass es so auch für die kleinste Münze einen Schein geben wird, wohingegen unter dem derzeit geltenden System viele darum betteln müssen.\n",
    "Es ist schade, dass ich die Scheine nicht zu Hause herstellen kann, aber das ist das Privileg des Staates, und wenn ich es täte, käme ich als Geldfälscher ins Gefängnis, ansonsten würde ich mir jeden Tag fünfzig machen und hätte dann am Ende des Monats genug, um Haus und Einkäufe zu bezahlen.\n",
    "Nicht alle haben dieselben Rechte wie die Regierung ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cfetjbQC4vy"
   },
   "outputs": [],
   "source": [
    "test_ST = pipeline_pt(ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dQVgXNvqrT-"
   },
   "outputs": [],
   "source": [
    "test_MT = pipeline_de(MT)\n",
    "test_HT = pipeline_de(HT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CBRyzn-sKZv",
    "outputId": "97ba2439-015d-4de8-9919-015465625d11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ST.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0drOsYrsYPz",
    "outputId": "941d192b-3780-45f0-9865-e35c9e32e23f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_MT.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9hSZFeZsZQa",
    "outputId": "d2e848fa-5029-404a-911d-2ec4af6af3c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_HT.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "N4_XGagdQrFx",
    "outputId": "9b8c1acd-55fc-42ef-ae01-f364cb60cb1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Es ist immer interessant, auf die eine oder andere Weise eine alte Ausgabe der Zeitung „Jornal do Comércio” zu finden, selbst wenn es nur ein alter Ausschnitt ist.\n",
      "2: Ich stelle mir vor, wie Félix Pacheco, der ihre Geschichte schreibt, mit seiner Geduld, seiner Scharfsinnigkeit und seiner Einsicht als Künstler und Historiker köstliche Momente erlebt haben muss, als er diesen oder jenen Artikel, diese oder jene Nachricht oder sogar eine einfache Anzeige gefunden hat!\n",
      "3: Ich hoffe, dass ich bis 1921 lebe, um die Geschichte des alten Blattes zu lesen, die sein derzeitiger Direktor schreibt.\n",
      "4: Nach dem, was er letztes Jahr gezeigt hat, nach dem, was er über die Ursprünge der fast hundertjährigen Tageszeitung gesagt hat, können wir uns vorstellen, wie interessant das von Félix Pacheco erzählte Leben der Zeitung sein wird.\n",
      "5: Das kam mir in den Sinn, weil mir vor einigen Monaten ein guter alter Mann aus meiner Nachbarschaft, der leidenschaftlich gerne Zeitung liest, eine Menge Zeitungsausschnitte aus verschiedenen Zeitungen und Epochen geschenkt hat.\n",
      "6: Darunter waren viele Fortsetzungsromane aus dem Jornal, die vierzig Jahre und älter waren.\n",
      "7: Dieser gute alte Mann, „Seu” Chiquinho, wie er familiär genannt wurde, scheint mir diese Relikte testamentarisch vermacht zu haben, denn er starb kurz darauf im Hospital da Ordem Terceira, isoliert von seinen Angehörigen, umgeben von gleichgültigen Krankenschwestern und ohne die Gesellschaft seiner geliebten Fortsetzungsromane und Zeitungsausschnitte, die er über vierzig Jahre lang gesammelt hatte.\n",
      "8: Ich konnte nicht herausfinden, wer die Autoren der Zeitungsausschnitte waren, die er mir geschenkt hatte, da sie alle mit Pseudonymen signiert waren.\n",
      "9: Damals waren, soweit ich weiß, mehr oder weniger, aufgrund der wenig zuverlässigen Überlieferung, die angesagtesten Autoren in diesem Geschäft:\n",
      "10: Augusto de Castro, Zaluar, César Muzzio und, glaube ich, der alte Luís de Castro selbst.\n",
      "11: Ich habe versucht, die erhaltenen Stücke zu lesen, aber ich konnte es nicht.\n",
      "12: Nichts altert so schnell wie das, was wir in Zeitungen noch immer als Humor, Leichtigkeit, Witz usw. bezeichnen.\n",
      "13: Alle Ausschnitte, die ich erhalten habe, hatten zu ihrer Zeit wohl diesen Anspruch und wurden als solche geschätzt, aber ich fand sie einschläfernd.\n",
      "14: Ich weiß nicht, was dieses Genre der Feuilletons so streng aktuell, so sehr dem Moment, der Minute, in der es geschrieben wird, verbunden ist, dass es, sobald dieser flüchtige Augenblick vorbei ist, sofort schal wird und seinen ganzen Geschmack verliert.\n",
      "15: Bedenken Sie, dass ich schon Feuilletons geschrieben habe, schreibe und schreiben werde...\n",
      "16: Aber...\n",
      "17: Es ist ein Genre, das immer nach dem aktuellsten Ereignis oder der aktuellsten Begebenheit sucht, nach dem, was die Oberflächlichkeit aller am meisten interessiert, und das voller Anspielungen auf vergängliche Personen und Dinge sein muss, damit es Erfolg hat.\n",
      "18: Die Fußnoten dürfen nicht auf den vulgären Alltag verzichten, sie dürfen sich weder weiter nach vorne noch weiter nach hinten erheben.\n",
      "19: Das ist es!\n",
      "20: Es ist der Elefant von Franck Brown oder die Ankunft der Mission aus dem Königreich Sion.\n",
      "21: Wer wird sich in dreißig Jahren noch an den Elefanten des großen Hu-Hep-Tu, Botschafter eines Königreichs in Indochina, erinnern?\n",
      "22: Niemand wird mehr Interesse an solchen Kuriositäten haben, geschweige denn an den Überlegungen, die sie in diesem oder jenem Werk anstellen.\n",
      "23: Solange ihre Autoren noch leben, verbinden wir die Feuilletons unempfindlich mit ihnen und können sie lesen; aber da die Autoren derjenigen, die sie mir gegeben hatten, längst tot und fast vergessen waren, hatten die Fußnoten von vor vierzig Jahren keinen Reiz mehr und waren undurchdringlich.\n",
      "24: Dennoch hat mir das Geschenk des alten „Seu” Chiquinho Freude bereitet.\n",
      "25: Und wissen Sie, wo ich es gefunden habe?\n",
      "26: In den Nachnamen und Anzeigen auf den Rückseiten der humorvollen, alten und berühmten Journalisten jener Jahre.\n",
      "27: Ich mochte die Spitznamen schon immer.\n",
      "28: Man sagt, sie seien eine Besonderheit Brasiliens, insbesondere von Rio de Janeiro.\n",
      "29: Ob es nun eine gute oder schlechte Sitte ist, sicher ist, dass sie originell ist, deshalb mag ich sie.\n",
      "30: Ich habe mir sehr gewünscht, in den Schnipseln, mit denen ich mich beschäftige, etwas von dem berühmten „Mal das Vinhas” oder dem nicht weniger berühmten Príncipe Ubá II, d’África zu finden.\n",
      "31: Ich hätte sehr gerne einen von letzterem gesehen, denn mir wurde erzählt, dass man sich nichts Sinnloseres und Absurderes vorstellen kann.\n",
      "32: Die Art und Weise, wie er sie veröffentlichte, ist erwähnenswert und verdient es, festgehalten zu werden.\n",
      "33: Er, der Prinz Ubá, schrieb einen Comicstrip nach dem anderen und klebte sie dann hintereinander.\n",
      "34: Er machte eine Art Rolle und brachte sie zum Zeitungskiosk.\n",
      "35: Wie viel kostet das?, fragte er.\n",
      "36: Da der Prinz dieses Geld nicht in der Tasche hatte, versuchte er, die „Länge” des Artikels zu verkürzen.\n",
      "37: Er bat um eine Schere, schnitt einen guten Teil heraus, unterschrieb erneut und fragte wieder:\n",
      "38: Wie viel?\n",
      "39: Fünfundzwanzigtausend Réis, antworteten sie.\n",
      "40: Da der afrikanische Edelmann nicht über einen solchen Betrag verfügte, schnitt er noch einmal, dann noch ein drittes Mal, bis der Preis „auf Anfrage“ auf die vier- oder fünftausend Réis sank, die er in seinen Taschen hatte.\n",
      "41: Er unterschrieb, ohne sich um den Sinn oder die Schlussfolgerung seines Textes zu kümmern, und ging zum Largo da Sé, um den schwarzen Frauen, die ihn respektierten und verehrten, Geschichten zu erzählen, immer mit seinem Stock und Regenschirm und feierlich bedeckt mit seinem grauen Zylinder.\n",
      "42: Ich habe keinen einzigen Ausschnitt dieser beiden berühmten Mitarbeiter der ursprünglichen Rubrik der Zeitung gefunden, aber ich bin auf etwas Interessantes gestoßen.\n",
      "43: In der Ausgabe vom 11. Juli 1879 gibt es einen Artikel mit dem vielsagenden Titel:\n",
      "44: „Eine ausgezeichnete Mütze”.\n",
      "45: Im Slang der damaligen Zeit bedeutete „Mütze” Trunkenheit.\n",
      "46: Der Artikel begann so:\n",
      "47: Am Samstagabend, schon spät, betrat jemand die Konditorei in der Rua Gonçalves Dias, der die „seltene Tugend” besitzt, in diesen Wintertagen warm angezogen zu sein.\n",
      "48: Weiter hieß es in Bezug auf diese Person:\n",
      "49: ... der Verkäufer weigerte sich, den ‚Potentaten’ zu bedienen.\n",
      "50: Er führte ihn zur Tür und schloss sie vorsichtig hinter den hochwohlgeborenen Fersen der ‚fröhlichen’ Gestalt.\n",
      "51: Am Ende forderte der Verfasser den Kaiser auf, seine Trauer noch zu verstärken, und unterschrieb mit:\n",
      "52: „Die beschämte Nation”.\n",
      "53: Wer war wohl der „Mützenmann”?\n",
      "54: Auf jeden Fall kann man sagen, dass, wenn sich die Sitten nicht geändert haben, heute niemand mehr an die „Apedidos” denken würde, um sich mit solchen Dingen zu befassen.\n",
      "55: Zum Glück...\n",
      "56: Es gibt noch einen weiteren „Apedido” mit dem Titel „Um camas” (Ein Bett).\n",
      "57: Er stammt vom 12. Oktober desselben Jahres wie der vorherige.\n",
      "58: Er beginnt wie folgt:\n",
      "59: Nur Cícero und elende Menschen kommen zum zweiten Mal mit ihrem Gequake, usw., usw.\n",
      "60: Dieser ist von der heftigen Sorte und endet mit der folgenden „guaiamu”-Herausforderung:\n",
      "61: Ich stehe vor Santa Efigênia, hast du gesehen, du Totenkopf.\n",
      "62: Ganz in der Nähe dieses „Apedido”, „nagoa” oder „santa-rita”, dieses „bittenden” Capoeira, gibt es einen anderen, voller Feinheit und Schmeichelei.\n",
      "63: Ironie des Seitenaufbaus...\n",
      "64: Seht nur:\n",
      "65: Die Erfahrungen mit Curare.\n",
      "66: Im Vertrauen auf die Unparteilichkeit von Herrn Doktor Nuno de Andrade halte ich es für die beste und sinnvollste Art der Diskussion, sich auf die vorliegenden Fakten zu stützen, daher lade ich Seine Exzellenz ein, ins Museum zu kommen, um diese zu überprüfen und zu diskutieren, wobei ich sicher bin, dass er von mir und von Doktor Jobert einen herzlichen Empfang finden wird.\n",
      "67: Doktor Lacerda Filho.\n",
      "68: Das ist interessant, dachte ich mir, dieser Dr. Nuno de Andrade hat viele „Werdegänge“ hinter sich!\n",
      "69: Ich wusste, dass er Finanzfachmann und Ökonom war, 1878 beschäftigte er sich mit toxikologischen Diskussionen oder ähnlichen Dingen, vielleicht ist er sogar Arzt?\n",
      "70: Ich suchte in Os Fastos do Museu Nacional von Dr. J. B. de Lacerda, um mich über die Angelegenheit zu informieren, fand aber nichts, außer dass Dr. Jobert ein Bohemien war.\n",
      "71: Das sagt so viel, dass...\n",
      "72: Allerdings wird darin eine sehr kuriose Anekdote erzählt, die zwar nichts mit dem Fall zu tun hat, die ich aber dennoch gerne wiedergeben möchte.\n",
      "73: Agassiz hielt 1864 in Anwesenheit des Kaisers eine Vorlesung, die von einem riesigen Publikum besucht wurde, darunter auch Damen der Gesellschaft, die sich damals für die Eiszeit, Findlinge und alpinen Moränen interessierten.\n",
      "74: Nach der Vorlesung bat der große Naturforscher die Anwesenden, ihre Fragen zu stellen, damit er sie beantworten könne.\n",
      "75: Da erhob sich ein gewisser Dr. Carvalho, Professor für Therapeutik an der Medizinischen Fakultät, und begann ungeniert zu erklären, dass all dies Unsinn sei, er wisse all diese Dinge, usw., usw.\n",
      "76: Der Kaiser zog sich zurück und wurde von den anderen Gästen begleitet.\n",
      "77: Carvalho jedoch schimpfte weiter.\n",
      "78: Herr Doktor Lacerda erzählt, dass der Therapeut Carvalho von seinem Lehrstuhl aus verkündete, der Zuckerhut habe ein ganglionäres Nervensystem, auch Eindrücke und Gefühle, die er nicht äußern könne, und andere noch kuriosere Dinge.\n",
      "79: Anscheinend hat dieser Doktor Carvalho die von ihm gelehrte Therapie nie bei anderen angewendet.\n",
      "80: Es ist anzunehmen, dass er innerhalb eines Jahres Rio de Janeiro entvölkert hätte, wenn er dies getan hätte...\n",
      "81: Und wenn schon die Namen, die ich in den mir überlassenen Zeitungsausschnitten gefunden habe, so komisch und suggestiv sind, stehen die Anzeigen, die ich darin gefunden habe, ihnen in nichts nach.\n",
      "82: Ich habe diejenigen aufbewahrt, die sich mit Sklaven befassen.\n",
      "83: Schauen wir mal.\n",
      "84: Secundino da Cunha, ein damals ordnungsgemäß zugelassener Auktionator, kündigte am 20. Januar 1868 an, neben Möbeln, einem Klavier, Schmuck und einer Küchenausstattung fünfzehn Sklaven „beiderlei Geschlechts, allesamt gute Stücke” zu verkaufen.\n",
      "85: Er wies besonders „auf die Sklaven hin, da dies eine seltene Gelegenheit sei und obwohl die Redlichkeit aller Sklaven von Herrn Freitas anerkannt sei, seien sie dennoch zu empfehlen, da alle von ihnen begabte Dienstmädchen, Köchinnen, Handwerker und Landarbeiter seien”.\n",
      "86: Die Hervorhebung stammt von mir, aber alles, einschließlich des Wortlauts, stammt aus der Anzeige.\n",
      "87: Klingt das nicht, als wäre es vor zweitausend Jahren gewesen?\n",
      "88: Das war es aber nicht.\n",
      "89: Eine solche Versteigerung fand am 29. Januar 1868, vor fünfzig Jahren und Monaten, in Rio de Janeiro statt, am Mittwoch, in der Residenz von Herrn Tomás Francisco de Freitas, Rua dos Andradas 48, im Obergeschoss.\n",
      "90: Herr Freitas reiste nach Europa, um sich um seine Gesundheit zu kümmern.\n",
      "91: Gott gebe ihm ewigen Frieden!\n",
      "92: Es gibt noch eine ähnliche Anzeige, aber der Auktionator ist ein Herr A. F. Casais.\n",
      "93: Im selben Monat und Jahr, jedoch am 21., verkaufte er unter dem Hammer „verschiedene Sklaven mit Handwerksberufen und Begabungen“ usw. usw.\n",
      "94: Monate zuvor, am 10. November des Vorjahres, kaufte jemand in der Rua da Alfândega Nr. 100, Sobrado, Sklaven im Alter von 18 bis 36 Jahren, um sie freizukaufen und als Soldaten einzustellen.\n",
      "95: Wir befanden uns mitten im Paraguayanischen Krieg, und die Patrioten, die nicht dorthin gehen wollten, um zu sterben, stellten Ersatzleute, die an ihrer Stelle gegen Lopez kämpften.\n",
      "96: Es war ein eigentümlicher Kriegsgewinn jener Zeit.\n",
      "97: Jeder hat seinen...\n",
      "98: Ich erwarte keine Antwort.\n",
      "99: Ich kehre zu meinen alten Papieren zurück...\n",
      "100: Bis bald.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(test_MT.sentences, 1):\n",
    "    print(f\"{i}: {sentence.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "WLPYQ9v-QYxb",
    "outputId": "700d6fa9-8bb2-45a7-cfae-93f54dfbbe4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Es ist für mich immer von Interesse, auf diese oder andere Weise ein altes Jornal do Comércio zu finden, auch nur einen alten Ausschnitt davon.\n",
      "2: Ich stelle mir vor, wie Félix Pacheco, der gerade die Geschichte des Jornal zusammenschreibt, mit seiner Geduld, seinem Scharfsinn und seinem Verstand als Künstler und Historiker, genüssliche Momente im Auffinden dieses oder jenes Artikels, von Nachrichten oder einer einfachen Anzeige verbracht haben muss.\n",
      "3: Ich erwarte mir schon, bis 1921 zu leben, um die Geschichte des alten Mediums zu lesen, die sein derzeitiger Direktor gerade verfasst.\n",
      "4: Durch das, was uns das vergangene Jahr gezeigt hat, was es uns von den Anfängen der circa täglichen Hundertjahrfeier gesagt hat, können wir uns ausrechnen, dass das verstrichene Leben des Journals, erzählt von Félix Pacheco, keine spannende Angelegenheit sein wird.\n",
      "5: Deswegen eilte mir diesbezüglich vor Monaten ein guter Alter aus meiner Nachbarschaft zur Hilfe, ein begeisterter Zeitungsleser, der mir einen Haufen Ausschnitte diverser Zeitungen aus unterschiedlichen Zeitaltern gab.\n",
      "6: Darunter waren viele Feuilletons des Jornal, die vierzig Jahre und älter sind.\n",
      "7: Dieser gute Alte, Seu Chiquinho, wie er allgemein bekannt war, machte den Eindruck, als ob er mir diese Reliquien im Testament hinterließ, denn kurz danach starb er, im Spital des Dritten Ordens, abgeschieden von den Seinen, umgeben von gleichgültigen Krankenschwestern, und ohne wenigstens die Gegenwart seiner geliebten Feuilletons und Zeitungsausschnitte, die er seit mehr als vierzig Jahren gesammelt hatte.\n",
      "8: Ich konnte nicht herausfinden, wer die Autoren der Feuilletonbeiträge waren, die er mir offeriert hatte, denn alle waren mit Pseudonymen unterzeichnet.\n",
      "9: Zu jener Zeit waren, wie ich mehr oder weniger aufgrund kaum beglaubigter Überlieferungen weiß, die bekanntesten Männer im Feuilletongeschäft:\n",
      "10: Augusto de Castro, Zaluar, César Muzzio und, wie ich glaube, der alte Luís de Castro selbst.\n",
      "11: Ich habe versucht, die zu lesen, die ich bekommen hatte, aber ich schaffte es nicht.\n",
      "12: Es gibt nichts, das so schnell altert wie das, was wir noch in Zeitungen vorbringen: Humor, Leichtigkeit, Witz, etc.\n",
      "13: Alle Ausschnitte, die ich erhalten habe, müssen zu ihrer Zeit diese Ansprüche gehabt haben und als solche geschätzt worden sein, aber ich fand sie einschläfernd.\n",
      "14: Ich weiß nicht, was diesen Typ Feuilleton so strikt mit dem Aktuellen, dem Moment, der Minute, in der er geschrieben wird, verbindet, dass er, sobald dieser flüchtige Augenblick vergeht, verdirbt und jeden Geschmack verliert.\n",
      "15: Bedenken Sie, dass ich auch schon Feuilletonbeiträge gemacht habe, mache, und machen werde ...\n",
      "16: Aber ...\n",
      "17: Es ist ein Genre, das immer den aktuellsten Tatsachen oder Ereignissen nachjagt, denen, deren Belanglosigkeit alle interessiert und die voll von Anspielungen auf Personen und vergängliche Dinge sein müssen, damit sie vom Erfolg angehaucht werden.\n",
      "18: Die Fußnoten können nicht auf den gewöhnlichen Alltag verzichten, sie können sich nicht vorwärtsbewegen, aber auch nicht weiter zurück.\n",
      "19: Es ist hier!\n",
      "20: Es ist der Elefant von Franck Brown oder die Ankunft der Gesandtschaft des Königreichs Siam.\n",
      "21: Wer wird sich in dreißig Jahren noch an diesen Elefanten des großen Hu-Hep-Tu, Botschafter des Königreichs von Indochina, erinnern?\n",
      "22: Wird niemand mehr Interesse für solche Kuriositäten haben und noch weniger für die Überlegungen, die über das eine oder das andere angestellt wurden?\n",
      "23: Wenn seine Autoren noch leben, verbinden wir unsensiblerweise die Feuilletons mit ihnen und wir können sie noch lesen, aber sind sie tot und so gut wie vergessen, so wie die Autoren derer, die man mir gegeben hat, verfügen die vierzig Jahre alten Fußnoten über keine Anziehungskraft mehr und bleiben mir unzugänglich.\n",
      "24: In der Zwischenzeit hörte die Gabe des alten Seu Chiquinho nicht auf, mir Vergnügen zu bereiten.\n",
      "25: Und wissen Sie, wo ich es gefunden habe?\n",
      "26: In den Einschaltungen und Anzeigen, die auf der Rückseite der humorvollen, alten und berühmten Journalisten dieser Jahre standen.\n",
      "27: Immer schon haben mir die Lesereinschaltungen gefallen.\n",
      "28: Man sagt, dass sie eine brasilianische Besonderheit sind, speziell in Rio de Janeiro.\n",
      "29: Mag das nun eine gute oder schlechte Gepflogenheit sein, sicherlich ist es eine originelle Sache, und deswegen gefallen sie mir.\n",
      "30: Ich wünschte mir sehr, in den Ausschnitten, die ich gerade behandelt habe, etwas über den berühmten Wunderheiler des „Mal das Vinhas“  oder über den nicht weniger berühmten Prinzen Obá II. von Afrika  zu finden.\n",
      "31: Ich würde sehr gerne etwas von Letzterem sehen, da man sich laut einigen Erzählungen nichts Sinnloseres und Schrulligeres vorstellen kann.\n",
      "32: Sein Publikationsprozess ist erinnungs- und aufzeichnungswürdig.\n",
      "33: Er, der Prinz Obá, beschrieb einen Papierstreifen nach dem anderen, und danach stückelte er einen an den anderen.\n",
      "34: Er machte eine Art Spule und nahm die Rolle zum Schalter des Jornal mit.\n",
      "35: Wieviel kostet das?, fragte er immer.\n",
      "36: Der Prinz hatte dieses Geld nicht in den Taschen, er befasste sich also damit, die „Ausmaße“ des Artikels zu verringern.\n",
      "37: Er bat um eine Schere, schnitt ein gutes Stück ab, unterschrieb erneut und fragte wieder:\n",
      "38: Wieviel kostet das?\n",
      "39: 25.000 Reis, antworteten sie ihm.\n",
      "40: Nicht im Besitz eines derartigen Betrags amputierte der afrikanische Edelmann den „Darm“ noch einmal, noch ein drittes Mal, bis der Preis der erbetenen Einschaltung den Preis von vier- oder fünftausend Reis erreichte, die er bei sich hatte.\n",
      "41: Kaum war die Unterschrift hinzugefügt, ohne sich über den Sinn, über die Konklusion, die er mit dem Geschriebenen erreichen wollte, den Kopf zu zerbrechen, und da machte er sich schon auf dem Weg zum Largo da Sé, wo er den schwarzen Mädchen, die ihn respektierten und verehrten, Geschichten erzählte, immer mit Spazierstock und Regenschirm und mit seinem grauen Zylinder förmlich auf dem Kopf.\n",
      "42: Ich habe kein Fragment dieser zwei berühmten Mitarbeiter der originellen Sektion des Jornal gefunden, aber ich bin auf eine interessante Sache gestoßen.\n",
      "43: In der Ausgabe vom 11. Juli 1879 gibt es eine Einschaltung, die diesen verheißungsvollen Titel trägt:\n",
      "44: „Ein überaus exzellenter Dusel“.\n",
      "45: Im Jargon dieser Zeit war Dusel ein Rausch.\n",
      "46: Es fing wie folgt an:\n",
      "47: Samstagabend, schon recht spät, betrat jemand die Konditorei in der Rua Gonçalves Dias, jemand, der die ,seltene Tugend‘ besitzt, in diesen Winterzeiten recht beduselt spazieren zu gehen.\n",
      "48: Weiter vorne sagte man, in Bezug auf diesen jemand:\n",
      "49: … der Verkäufer vermied es, den ,Potentaten‘ zu bedienen.\n",
      "50: Er brachte ihn zur Tür, die er bald sorgfältig vor den ausgezeichnetsten Fersen der ,fröhlichen‘ Gestalt dieser Situation schloss.“\n",
      "51: Abschließend bat er den Kaiser, weiter sein Trauergewand zu tragen, und unterzeichnete:\n",
      "52: „Die beschämte Nation.“\n",
      "53: Wer war wohl der mit dem „Dusel“?\n",
      "54: Auf alle Fälle kann man sagen, dass, sollten sich die Gebräuchlichkeiten nicht geändert haben, es heute niemanden gibt, der sich an die Einschaltungen erinnern könnte, die eine ähnliche Sache behandeln.\n",
      "55: Wie dem auch sei …\n",
      "56: Es gibt eine andere Einschaltung, die als Titel „Betten“ hat.\n",
      "57: Sie ist vom 12. Oktober des gleichen Jahres wie die vorige.\n",
      "58: Dies ist der Anfang:\n",
      "59: Allein geht Cicero, und miserabel, der zum zweiten Mal mit seinem Spott kommt, etc. etc.\n",
      "60: Diese ist von heftigem Charakter und endet mit folgender typischer Herausforderung der Gruppierung der Guaiamu.\n",
      "61: Ich warte vor der Kirche Santa Efigênia, ihr habt es gesehen, Totenschädel.\n",
      "62: Ganz nah bei dieser Einschaltung, „Nagoa“  oder „Santa Rita“, von diesem Capoeira-„Antragssteller“, steht diese andere voller Fingerspitzengefühl und Zartheit.\n",
      "63: Eine Ironie der Paginierung ...\n",
      "64: schauen Sie nur:\n",
      "65: „Die Erfahrungen mit dem Pfeilgift“\n",
      "66: Glaubt man an die Unparteilichkeit des Herrn Doktor Nuno de Andrade, halte ich es für die beste und nützlichste Art, in Anwesenheit von Fakten zu diskutieren, deswegen lade ich Eure Herrschaft ein, ins Museum zu kommen, um sie zu verifizieren und zu diskutieren, in der Gewissheit, von meiner Seite und von Doktor Jobert wärmstens in Empfang genommen zu werden.\n",
      "67: Doktor Lacerda Filho.\n",
      "68: Schau an, sagte ich hier zu mir, dieser Doktor Nuno de Andrade hatte viele „Avatare“.\n",
      "69: Ich kannte ihn als Finanzier, als Ökonom, 1878 widmete er sich toxikologischen Diskussionen oder ähnlichen Angelegenheiten, wer weiß, vielleicht war er selbst auch Arzt?\n",
      "70: Ich besorgte mir Os Fastos do Museu Nacional , von Doktor J. B. de Lacerda, um zu sehen, ob ich mich über die Frage informieren könnte, aber ich fand nichts, außer, dass Doktor Jobert ein Bohémien war.\n",
      "71: Das sagt vieles aus ...\n",
      "72: In ihnen wird jedoch eine sehr erstaunliche Anekdote erzählt, bezüglich der ich mich, abgesehen davon, dass sie nichts mit dem Fall zu tun hat, nicht für das Vergnügen entschuldige, sie hier zu erzählen.\n",
      "73: Agassiz  veranstaltete 1864, in Anwesenheit des Kaisers, einen Vortrag, für den er immense Unterstützung erfahren hatte, sogar von den Damen der Gesellschaft, die sich damals für die Eiszeit, für erratische Blöcke und die alpinen Moränen interessierten.\n",
      "74: Nach Abschluss des Vortrags bat der große Naturalist die Umstehenden, ihre Zweifel vorzubringen, dann würde er sie erläutern.\n",
      "75: Es erhebt sich also ein Doktor Carvalho, Professor für Therapie an der Fakultät für Medizin, und beginnt auf barsche Weise vorzubringen, dass das alles ein alter Hut sei, er wusste all diese Dinge, etc., etc.\n",
      "76: Der Kaiser zieht sich zurück, gefolgt von einigen anderen Geladenen.\n",
      "77: Carvalho hingegen tobt weiter.\n",
      "78: Dann sagt Herr Doktor Lacerda, dass der Therapeut Carvalho von seinem Lehrstuhl aus predige, dass der Zuckerhut ein Nervensystem mit Ganglien hätte, auch Eindrücke und Gefühle, die er nicht externalisieren könnte, und andere, noch kuriosere Dinge.\n",
      "79: Wie es scheint, wandte dieser Doktor Carvalho die Therapiemethoden, die er lehrte, nie an anderen an.\n",
      "80: Es tut gut daran zu glauben, dass er, hätte er sie praktiziert, Rio de Janeiro innerhalb von einem Jahr entvölkert hätte …\n",
      "81: So komisch und anregend sind die Einschaltungen, die ich in den Ausschnitten des Jornal, die mir gegeben wurden, gefunden habe, nicht weniger sind es die Werbeanzeigen, die ich in ihnen entdeckt habe.\n",
      "82: Ich habe die, die Sklaven behandeln, behalten.\n",
      "83: Lasst uns einen Blick darauf werfen.\n",
      "84: Secundino da Cunha, ein Auktionator dieser Zeit, ordnungsgemäß berechtigt, verkündete am 20 Jänner 1868, dass er außer Möbeln, einem Piano, Schmuck und Küchengeschirr fünfzehn Sklaven verkaufe, „beider Geschlechter, alles schöne Stücke“.\n",
      "85: Er lenkte vor allem „Aufmerksamkeit auf die Sklaven, da es sich um eine seltene Gelegenheit handelt, und auch wenn die Redlichkeit aller Sklaven des Herrn Freitas anerkannt ist, empfiehlt man sie, da sie fähige Haushaltshelferinnen, Köchinnen, Handwerksgesellen und Arbeitskräfte sind.“\n",
      "86: Die Kursivsetzung stammt von mir, aber alles, inklusive des Redaktionstexts, ist Teil der Anzeige.\n",
      "87: Kommt es einem nicht so vor, als ob sich das vor 2000 Jahren abgespielt hat?\n",
      "88: So war es aber nicht.\n",
      "89: Ein solche Versteigerung erfolgte am 29. Jänner 1868, vor fünfzig Jahren und Monaten, in der Stadt Rio de Janeiro, an einem Mittwoch, auf dem Anwesen des Herrn Tomás Francisco de Freitas, in der Rua dos Andradas 48, einem Stadthaus.\n",
      "90: Der Herr Freitas wollte nach Europa reisen, um sich um seine Gesundheit zu kümmern.\n",
      "91: Gott möge ihn in seinem heiligen Frieden bewahren!\n",
      "92: Es gibt eine ähnliche Anzeige, aber der Versteigerer ist ein Herr A. F. Casais.\n",
      "93: Im selben Jahr und Monat, jedoch am 21., „würden unterschiedliche Sklaven, mit Handwerken und Fähigkeiten“, etc., etc., unter den Hammer kommen.\n",
      "94: Monate davor, am 10. November des Vorjahres, kaufte jemand im Stadthaus der Rua da Alfândega Nr. 100 Sklaven im Alter von 18 und 36 Jahren, um sie zu befreien, damit sie ins Militär eintreten.\n",
      "95: Wir befanden uns mitten im Krieg mit Paraguay; und die Patrioten, die nicht dort sterben wollten, sorgten für Ersatz, der Lopez  statt ihnen bekämpfte.\n",
      "96: Es war ein spezieller Profit de Guerre dieses Zeitalters.\n",
      "97: Jedes einzelne hat seinen ...\n",
      "98: Ich erwarte keine Antwort.\n",
      "99: Ich kehre zu meinen alten Papieren zurück ...\n",
      "100: Bis bald.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(test_HT.sentences, 1):\n",
    "    print(f\"{i}: {sentence.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqLz_KWzsff3"
   },
   "outputs": [],
   "source": [
    "def check_sentence_alignment(test_ST, test_MT, test_HT):\n",
    "    \"\"\"\n",
    "    Compare sentences from Source Text (ST), Machine Translation (MT),\n",
    "    and Post-Edited Machine Translation (PEMT) to find alignment differences.\n",
    "\n",
    "    Args:\n",
    "        test_ST (object): Parsed output of the source text pipeline.\n",
    "        test_MT (object): Parsed output of the MT pipeline.\n",
    "        test_PEMT (object): Parsed output of the PEMT pipeline.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of misaligned sentence information.\n",
    "    \"\"\"\n",
    "    misalignments = []\n",
    "\n",
    "    # Extract sentences from the parsed objects\n",
    "    st_sentences = [sentence.text for sentence in test_ST.sentences]\n",
    "    mt_sentences = [sentence.text for sentence in test_MT.sentences]\n",
    "    ht_sentences = [sentence.text for sentence in test_HT.sentences]\n",
    "\n",
    "    # Find the length of the shortest text\n",
    "    min_length = min(len(st_sentences), len(mt_sentences), len(ht_sentences))\n",
    "\n",
    "    for i in range(min_length):\n",
    "        st_sentence = st_sentences[i]\n",
    "        mt_sentence = mt_sentences[i]\n",
    "        ht_sentence = ht_sentences[i]\n",
    "\n",
    "        if st_sentence != mt_sentence or st_sentence != ht_sentence:\n",
    "            misalignments.append({\n",
    "                \"index\": i + 1,\n",
    "                \"source\": st_sentence,\n",
    "                \"mt\": mt_sentence,\n",
    "                \"ht\": ht_sentence\n",
    "            })\n",
    "\n",
    "    return misalignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_20INzKte7N",
    "outputId": "b96ca96c-8eed-4a28-e253-04fe8391f30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "  Source: Aconteceu isto em Pernambuco.\n",
      "  MT: Das geschah in Pernambuco.\n",
      "  HT: Das Folgende trug sich in Pernambuco zu.\n",
      "Sentence 2:\n",
      "  Source: Não sei mesmo em que cidade, mas foi nas proximidades do Recife.\n",
      "  MT: Ich weiß nicht genau, in welcher Stadt, aber es war in der Nähe von Recife.\n",
      "  HT: Ich weiß nicht einmal, in welcher Stadt, jedenfalls aber war es in der Nähe von Recife.\n",
      "Sentence 3:\n",
      "  Source: Havia lá uma família muito rica, cujo chefe era o Barão de ***.\n",
      "  MT: Dort lebte eine sehr reiche Familie, deren Oberhaupt der Baron von *** war.\n",
      "  HT: Dort gab es eine sehr reiche Familie, deren Oberhaupt der Baron von *** war.\n",
      "Sentence 4:\n",
      "  Source: Tinha este muitas filhas e nenhum varão; e todos os bacharéis da redondeza cercavam as meninas de todas as homenagens.\n",
      "  MT: Er hatte viele Töchter, aber keinen einzigen Sohn, und alle Junggesellen aus der Umgebung umwarben die Mädchen mit allen Ehren.\n",
      "  HT: Dieser Mann hatte viele Töchter, aber keinen Sohn; und alle Junggesellen in der Umgebung machten den Mädchen den Hof.\n",
      "Sentence 5:\n",
      "  Source: Era o barão uma espécie Zé Bezerra, porquanto, sendo dono de uma grande usina de açúcar, dominava uma grande superfície ao derredor dela, marcando preços e emprestando dinheiro a bons juros sobre as futuras safras dos canaviais.\n",
      "  MT: Der Baron war eine Art Zé Bezerra, denn als Besitzer einer großen Zuckerfabrik beherrschte er ein großes Gebiet um diese herum, bestimmte die Preise und verlieh Geld zu guten Zinsen auf die zukünftigen Ernten der Zuckerrohrfelder.\n",
      "  HT: Der Baron war eine Art Zé Bezerra , denn als Besitzer einer großen Zuckermühle war er Herr über große Ländereien, er bestimmte die Preise und verlieh Geld zu guten Zinsen gegen zukünftige Zuckerrohrernten.\n",
      "Sentence 6:\n",
      "  Source: Com uma fortuna imensa, ele afugentava os prováveis maridos de suas filhas que temiam fazer-lhe o sacramental pedido.\n",
      "  MT: Mit seinem immensen Vermögen schreckte er die potenziellen Ehemänner seiner Töchter ab, die sich nicht trauten, um ihre Hand anzuhalten.\n",
      "  HT: Mit seinem immensen Vermögen vertrieb er die potenziellen Ehemänner seiner Töchter, die sich nicht trauten, um ihre Hand anzuhalten.\n",
      "Sentence 7:\n",
      "  Source: Um belo dia, porém, houve um mais ousado que se animou a faze-lo.\n",
      "  MT: Eines schönen Tages jedoch wagte sich ein Mutiger, es zu tun.\n",
      "  HT: Eines schönen Tages aber wagte es doch einer.\n",
      "Sentence 8:\n",
      "  Source: Foi o doutor X, promotor da localidade, formado recentemente e capaz de tudo.\n",
      "  MT: Es war Doktor X, der örtliche Staatsanwalt, frisch ausgebildet und zu allem fähig.\n",
      "  HT: Es war Doktor X, der Staatsanwalt der Stadt, kürzlich graduiert und zu allem imstande.\n",
      "Sentence 9:\n",
      "  Source: O bacharelete vestiu-se com o melhor terno que tinha e foi até ao engenho do Barão de ***.\n",
      "  MT: Der junge Jurist zog seinen besten Anzug an und begab sich zur Mühle des Barons von ***.\n",
      "  HT: Der junge Mann wählte den besten Anzug, den er hatte, und begab sich zur Zuckerrohrplantage des Baron von ***.\n",
      "Sentence 10:\n",
      "  Source: O barão, conquanto fosse muito orgulhoso de seu título e da sua fortuna, era delicado e atencioso.\n",
      "  MT: Der Baron war zwar sehr stolz auf seinen Titel und sein Vermögen, aber er war auch feinfühlig und aufmerksam.\n",
      "  HT: Obwohl der Baron sehr stolz auf seinen Titel und sein Vermögen war, gab er sich taktvoll und zuvorkommend.\n",
      "Sentence 11:\n",
      "  Source: Ouviu com toda a polidez a exposição do bacharel.\n",
      "  MT: Er hörte sich die Ausführungen des Junggesellen höflich an.\n",
      "  HT: Höflich hörte er den Ausführungen des jungen Mannes zu.\n",
      "Sentence 12:\n",
      "  Source: Dizia este:\n",
      "  MT: Dieser sagte:\n",
      "  HT: Dieser sagte:\n",
      "Sentence 13:\n",
      "  Source: Animei-me a fazer-lhe este pedido, porquanto a minha situação social e a minha idade parecem mo permitir.\n",
      "  MT: Ich habe mich entschlossen, Ihnen diese Frage zu stellen, da meine soziale Stellung und mein Alter mir dies zu erlauben scheinen.\n",
      "  HT: Ich habe den Mut, an Sie heranzutreten, weil meine gesellschaftliche Stellung und mein Alter es mir zu erlauben scheinen.\n",
      "Sentence 14:\n",
      "  Source: O senhor barão, qualquer que seja a sua opinião, não se ofenderá com ele.\n",
      "  MT: Herr Baron, wie auch immer Sie entscheiden, nehmen Sie es mir bitte nicht übel.\n",
      "  HT: Was auch immer Ihre Ansicht sein mag, Herr Baron, Sie werden es nicht als Beleidigung auffassen.\n",
      "Sentence 15:\n",
      "  Source: Não é assim?\n",
      "  MT: Ist das nicht so?\n",
      "  HT: Nicht wahr?\n",
      "Sentence 16:\n",
      "  Source: Não há dúvida.\n",
      "  MT: Selbstverständlich.\n",
      "  HT: Ohne jeden Zweifel.\n",
      "Sentence 17:\n",
      "  Source: Mas com qual das minhas filhas o senhor deseja casar-se?\n",
      "  MT: Aber welche meiner Töchter möchten Sie heiraten?\n",
      "  HT: Aber welche meiner Töchter wollen Sie heiraten?\n",
      "Sentence 18:\n",
      "  Source: Irene.\n",
      "  MT: Irene.\n",
      "  HT: Doutora Irene.\n",
      "Sentence 19:\n",
      "  Source: O barão coçou as barbas e disse, após um instante:\n",
      "  MT: Der Baron kratzte sich am Bart und sagte nach einem Moment:\n",
      "  HT: Der Baron kratzte sich am Bart und sagte einen Augenblick später:\n",
      "Sentence 20:\n",
      "  Source: Não lhe posso conceder a mão de minha filha Irene.\n",
      "  MT: Ich kann Ihnen die Hand meiner Tochter Irene nicht geben.\n",
      "  HT: Ich kann Ihnen die Hand meiner Tochter Irene nicht gewähren.\n",
      "Sentence 21:\n",
      "  Source: Porque, barão?\n",
      "  MT: Warum, Baron?\n",
      "  HT: Weshalb nicht, Herr Baron?\n",
      "Sentence 22:\n",
      "  Source: Ela já é noiva do doutor Castrioto, deputado estadual.\n",
      "  MT: Sie ist bereits mit Doktor Castrioto, dem Abgeordneten, verlobt.\n",
      "  HT: Sie ist bereits mit Doutor Castrioto, dem Abgeordneten, verlobt.\n",
      "Sentence 23:\n",
      "  Source: O promotor pensou alguns minutos; o barão ficou suspenso, à espera da resposta do rapaz, até que este disse:\n",
      "  MT: Der Staatsanwalt dachte einige Minuten nach; der Baron blieb stehen und wartete auf die Antwort des jungen Mannes, bis dieser sagte:\n",
      "  HT: Der Staatsanwalt dachte einige Minuten lang nach, der Baron wartete mit Spannung auf die Antwort des jungen Mannes, bis dieser sagte:\n",
      "Sentence 24:\n",
      "  Source: Não faz mal.\n",
      "  MT: Das macht nichts.\n",
      "  HT: Das macht nichts.\n",
      "Sentence 25:\n",
      "  Source: Caso-me com a outra.\n",
      "  MT: Ich heirate die andere.\n",
      "  HT: Ich heirate die andere.\n",
      "Sentence 26:\n",
      "  Source: Qual?\n",
      "  MT: Welche?\n",
      "  HT: Welche?\n",
      "Sentence 27:\n",
      "  Source: A segunda.\n",
      "  MT: Die zweite.\n",
      "  HT: Die zweite.\n",
      "Sentence 28:\n",
      "  Source: A Inês?\n",
      "  MT: Inês?\n",
      "  HT: Inês?\n",
      "Sentence 29:\n",
      "  Source: Sim.\n",
      "  MT: Ja.\n",
      "  HT: Ja.\n",
      "Sentence 30:\n",
      "  Source: A Inês.\n",
      "  MT: Inês.\n",
      "  HT: Inês.\n"
     ]
    }
   ],
   "source": [
    "#Example usage:\n",
    "misaligned = check_sentence_alignment(test_ST, test_MT, test_HT)\n",
    "for item in misaligned:\n",
    "    print(f\"Sentence {item['index']}:\")\n",
    "    print(f\"  Source: {item['source']}\")\n",
    "    print(f\"  MT: {item['mt']}\")\n",
    "    print(f\"  HT: {item['ht']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuwGri7zSXfW"
   },
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWRPxIGj6m0o"
   },
   "outputs": [],
   "source": [
    "# Function to calculate statistics\n",
    "def calculate_statistics(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    num_sentences = len(doc.sentences)\n",
    "    words = [word.text for sentence in doc.sentences for word in sentence.words if word.upos != \"PUNCT\"] # counts only real words\n",
    "    num_words = len(words) # how many words in text\n",
    "    num_unique_words = len(set(words))\n",
    "    num_characters = len(doc.text) # number of char with whitespace also punctuation\n",
    "    #num_characters_no_space = len(doc.text.replace(\" \", \"\"))\n",
    "    num_unique_lemmas = len(set(word.lemma for sentence in doc.sentences for word in sentence.words if word.upos != \"PUNCT\")) # lemma of real words, no punct\n",
    "    type_token_ratio = num_unique_words / num_words #if num_words > 0 else 0 # number_of_unique_lemmas / number_of_all_lemmas\n",
    "    mean_sentence_length = num_words / num_sentences #if num_sentences > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"num_sentences\": num_sentences,\n",
    "        \"num_words\": num_words,\n",
    "        \"unique_words\": num_unique_words,\n",
    "        \"unique_lemmas\": num_unique_lemmas,\n",
    "        \"num_char with space\": num_characters,\n",
    "        #\"num_char no space\" : num_characters_no_space,\n",
    "        \"type_token_ratio\": round(type_token_ratio, 3),\n",
    "        \"mean_sentence_length\": round(mean_sentence_length, 2),\n",
    "\n",
    "        #\"lemmas\": set(word.lemma for sentence in doc.sentences for word in sentence.words if word.upos != \"PUNCT\"),\n",
    "        #\"number of all lemmas\": len([word.lemma for sentence in doc.sentences for word in sentence.words if word.upos != \"PUNCT\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfT8hJZJ6qss"
   },
   "outputs": [],
   "source": [
    "# Function to calculate average length difference between two texts\n",
    "def calculate_avg_length_diff(text1, text2, nlp1, nlp2):\n",
    "    doc1 = nlp1(text1)\n",
    "    doc2 = nlp2(text2)\n",
    "    sentence_lengths1 = [len(sentence.words) for sentence in doc1.sentences]\n",
    "    print(sentence_lengths1)\n",
    "    sentence_lengths2 = [len(sentence.words) for sentence in doc2.sentences]\n",
    "    print(sentence_lengths2)\n",
    "    length_differences = [abs(l1 - l2) for l1, l2 in zip(sentence_lengths1, sentence_lengths2)]\n",
    "    print(length_differences)\n",
    "    return np.mean(length_differences) if length_differences else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aBX2OK1J6uTJ"
   },
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "source_stats = calculate_statistics(ST, pipeline_pt)\n",
    "mt_stats = calculate_statistics(MT, pipeline_de)\n",
    "ht_stats = calculate_statistics(HT, pipeline_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-1tP0pqGAHs",
    "outputId": "2573441f-f9fc-47d0-b02e-1bc4651e7aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 33, 20, 41, 45, 17, 2, 4, 2, 4, 30, 13, 2, 19, 17, 14, 7, 18, 17, 22, 5]\n",
      "[32, 27, 17, 36, 47, 16, 2, 5, 2, 5, 27, 15, 1, 19, 16, 15, 5, 14, 15, 25, 6]\n",
      "[13, 6, 3, 5, 2, 1, 0, 1, 0, 1, 3, 2, 1, 0, 1, 1, 2, 4, 2, 3, 1]\n",
      "[45, 33, 20, 41, 45, 17, 2, 4, 2, 4, 30, 13, 2, 19, 17, 14, 7, 18, 17, 22, 5]\n",
      "[27, 29, 18, 36, 48, 16, 2, 5, 2, 5, 32, 14, 1, 19, 17, 19, 5, 14, 15, 23, 4]\n",
      "[18, 4, 2, 5, 3, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 5, 2, 4, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Calculate average length differences\n",
    "source_mt_diff = calculate_avg_length_diff(ST, MT, pipeline_pt, pipeline_de) # difference between ST & MT\n",
    "source_ht_diff = calculate_avg_length_diff(ST, HT, pipeline_pt, pipeline_de) # difference between ST & HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m50GyNLwTrUV",
    "outputId": "1b9aecda-ca0e-4797-d8d7-9a0479ab553e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 27, 17, 36, 47, 16, 2, 5, 2, 5, 27, 15, 1, 19, 16, 15, 5, 14, 15, 25, 6]\n",
      "[27, 29, 18, 36, 48, 16, 2, 5, 2, 5, 32, 14, 1, 19, 17, 19, 5, 14, 15, 23, 4]\n",
      "[5, 2, 1, 0, 1, 0, 0, 0, 0, 0, 5, 1, 0, 0, 1, 4, 0, 0, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "mt_ht_diff = calculate_avg_length_diff(MT, HT, pipeline_de, pipeline_de) # difference between MT & HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAIk-cyZ6yNj",
    "outputId": "963fe5f6-2d4f-4604-8616-5767570ce494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Text Statistics:\n",
      "{'num_sentences': 21, 'num_words': 312, 'unique_words': 187, 'unique_lemmas': 162, 'num_char with space': 1813, 'type_token_ratio': 0.599, 'mean_sentence_length': 14.86}\n",
      "\n",
      "MT Statistics:\n",
      "{'num_sentences': 21, 'num_words': 282, 'unique_words': 194, 'unique_lemmas': 158, 'num_char with space': 2010, 'type_token_ratio': 0.688, 'mean_sentence_length': 13.43}\n",
      "\n",
      "HT Statistics:\n",
      "{'num_sentences': 21, 'num_words': 282, 'unique_words': 203, 'unique_lemmas': 162, 'num_char with space': 1977, 'type_token_ratio': 0.72, 'mean_sentence_length': 13.43}\n",
      "\n",
      "HT with footnotes Statistics:\n",
      "\n",
      "Average Length Differences:\n",
      "Source-MT: 2.48\n",
      "Source-HT: 2.57\n",
      "MT-HT: 1.14\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Source Text Statistics:\")\n",
    "print(source_stats)\n",
    "print(\"\\nMT Statistics:\")\n",
    "print(mt_stats)\n",
    "print(\"\\nHT Statistics:\")\n",
    "print(ht_stats)\n",
    "print(\"\\nHT with footnotes Statistics:\")\n",
    "#print(ht_fn_stats)\n",
    "print(\"\\nAverage Length Differences:\")\n",
    "print(f\"Source-MT: {round(source_mt_diff, 2)}\")\n",
    "print(f\"Source-HT: {round(source_ht_diff, 2)}\")\n",
    "\n",
    "print(f\"MT-HT: {round(mt_ht_diff, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKt98rLfe-z0"
   },
   "outputs": [],
   "source": [
    "def print_latex_table(source_stats, mt_stats, ht_stats, source_mt_diff, source_ht_diff):\n",
    "    def fmt(val):\n",
    "        return round(val, 2) if isinstance(val, float) else val\n",
    "\n",
    "    print(\"      Number of sentences & {} & {} & {} \\\\\\\\\".format(\n",
    "        source_stats['num_sentences'], mt_stats['num_sentences'], ht_stats['num_sentences']))\n",
    "    print(\"      Total words & {} & {} & {} \\\\\\\\\".format(\n",
    "        source_stats['num_words'], mt_stats['num_words'], ht_stats['num_words']))\n",
    "    print(\"      Unique lemmata & {} & {} & {} \\\\\\\\\".format(\n",
    "        source_stats['unique_lemmas'], mt_stats['unique_lemmas'], ht_stats['unique_lemmas']))\n",
    "    print(\"      Characters & {} & {} & {} \\\\\\\\\".format(\n",
    "        source_stats['num_char with space'], mt_stats['num_char with space'], ht_stats['num_char with space']))\n",
    "    print(\"      TTR & {:.3f} & {:.3f} & {:.3f} \\\\\\\\\".format(\n",
    "        source_stats['type_token_ratio'], mt_stats['type_token_ratio'], ht_stats['type_token_ratio']))\n",
    "    print(\"      Mean sentence length & {:.2f} & {:.2f} & {:.2f} \\\\\\\\\".format(\n",
    "        source_stats['mean_sentence_length'], mt_stats['mean_sentence_length'], ht_stats['mean_sentence_length']))\n",
    "    print(\"      Average length difference & -- & {:.2f} & {:.2f} \\\\\\\\\".format(\n",
    "        source_mt_diff, source_ht_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAr8qS3-fCGH",
    "outputId": "80986855-e95b-4ccd-ef60-4e07c2f6c69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Number of sentences & 21 & 21 & 21 \\\\\n",
      "      Total words & 312 & 282 & 282 \\\\\n",
      "      Unique lemmata & 162 & 158 & 162 \\\\\n",
      "      Characters & 1813 & 2010 & 1977 \\\\\n",
      "      TTR & 0.599 & 0.688 & 0.720 \\\\\n",
      "      Mean sentence length & 14.86 & 13.43 & 13.43 \\\\\n",
      "      Average length difference & -- & 2.48 & 2.57 \\\\\n"
     ]
    }
   ],
   "source": [
    "print_latex_table(source_stats, mt_stats, ht_stats, source_mt_diff, source_ht_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6fMjRMUhRgi"
   },
   "source": [
    "# Save parallel data TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEsBYf8chSZ3"
   },
   "outputs": [],
   "source": [
    "def extract_sentences(document):\n",
    "    \"\"\"\n",
    "    Extracts full sentences (with punctuation) from a Stanza document object.\n",
    "\n",
    "    Args:\n",
    "        document: Stanza processed Document object.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Extracted sentences as strings.\n",
    "    \"\"\"\n",
    "    return [sentence.text for sentence in document.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJ2Wr5zqhWdp"
   },
   "outputs": [],
   "source": [
    "mt_sentences = extract_sentences(test_MT)\n",
    "ht_sentences = extract_sentences(test_HT)\n",
    "st_sentences = extract_sentences(test_ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4-nQOi6hZpc",
    "outputId": "14c8d52c-1ed8-43c0-b2f1-6de960ef76b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ich lerne sehr gerne etwas über Finanzen aus Zeitungsartikeln.',\n",
       " 'Es gibt keine Diskussion zu diesem Thema, die ich nicht verfolge.',\n",
       " 'Derzeit gibt es eine solche Diskussion, die den Kongress, den Senat, die Zeitungen und die Bevölkerung begeistert, nämlich über Papiergeld.',\n",
       " 'Der Präsident der Republik hat angesichts der schwierigen Lage, in der sich die Nation befindet, den Kongress um die Genehmigung zur Ausgabe einer großen Menge davon gebeten; oder anders gesagt: Er hat einen befreundeten Abgeordneten einen Gesetzentwurf vorlegen lassen, der dies genehmigt.',\n",
       " 'Sofort hagelte es Kritik, dass diese ständige Ausgabe von Papiergeld unseren Geldmarkt demoralisiere, dass er mit Gold oder mit Papier, das in Gold umgewandelt werden könne, saniert werden müsse, usw., usw.',\n",
       " 'Ich verstehe nichts von diesen Dingen, aber ich werde meine bescheidene Meinung dazu äußern.',\n",
       " 'Ich halte diese Leute für unrecht, denn Gold ist Gold wert, und wenn Papier aufgrund eines Regierungsdekrets dem Gold gleichwertig ist, gibt es keinen Grund zur Aufregung.',\n",
       " 'Darüber hinaus will dieselbe Regierung angesichts des Geldmangels eine Emissions- und Diskontbank schaffen.',\n",
       " 'Es wundert mich sehr, dass dieser Mangel erst jetzt bemerkt wurde.',\n",
       " 'Ich spüre ihn schon seit langem und sehr deutlich, meine Herren.',\n",
       " 'Aber ... wenn es an Bargeld mangelt, sollte man meiner Meinung nach die Geldmenge erhöhen.',\n",
       " 'Gold ist selbst in Brasilien, wo es angeblich überall Minen gibt, eine Seltenheit, aber Papier ist leicht zu beschaffen und relativ billig.',\n",
       " 'Außerdem ist anzunehmen, dass, wenn die Regierung den Papiergeldumlauf erhöht, etwas davon auch zu uns gelangt.',\n",
       " 'Und das Gold?',\n",
       " 'Das landet sofort in den Kassen der Banken und nur die Millionäre werden es zu Gesicht bekommen.',\n",
       " 'Wenn der Staat klug sein und das Glück des Volkes fördern will, muss er so schnell wie möglich den Papiergeldumlauf erhöhen, nicht um 500 Millionen, sondern um so viele Millionen, wie viele Einwohner der weise Doktor Bulhões bei seiner Volkszählung in diesem riesigen Brasilien findet.',\n",
       " 'Es ist zu hoffen, dass dann jeder einen Zehn-Cent-Schein bekommt, während unter dem derzeitigen System viele um Almosen betteln.',\n",
       " 'Ich bedaure, dass ich sie nicht zu Hause herstellen kann, denn dies ist ein Privileg des Staates, und wenn ich es täte, würde ich als Falschmünzer im Gefängnis landen, aber wenn es nicht so wäre, würde ich jeden Tag einen Fünfzigerschein herstellen und am Ende des Monats hätte ich genug, um die Miete und den Ladenbesitzer zu bezahlen.',\n",
       " 'Nicht jeder hat die Rechte der Regierung...']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNeOlOqIP8Db"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_parallel_data(file_path, source_sentences, target_sentences):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\", newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=\"\\t\")\n",
    "        for src, tgt in zip(source_sentences, target_sentences):\n",
    "            writer.writerow([src, tgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7603y_9jP_iK"
   },
   "outputs": [],
   "source": [
    "# Save MT–HT\n",
    "save_parallel_data(\"mt_ht.tsv\", mt_sentences, ht_sentences)\n",
    "\n",
    "# Save ST–HT (optional, for analysis)\n",
    "save_parallel_data(\"st_ht.tsv\", st_sentences, ht_sentences)\n",
    "\n",
    "# Save ST-MT\n",
    "save_parallel_data(\"papel-moeda_st_mt.tsv\", st_sentences, mt_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "FJI6IIjgQTa9",
    "outputId": "bbfb625e-3d65-41d7-c2d2-0ee2d45f8c57"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4a0ef5a4-642c-490e-af02-1abcef79ba48\", \"mt_ht.tsv\", 23908)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_0cc830f1-d3f7-4054-b99b-6d99a64cefe1\", \"st_ht.tsv\", 22471)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"mt_ht.tsv\")\n",
    "files.download(\"st_ht.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "zX2VCLuHxh9s",
    "outputId": "4b558905-533d-4ae0-e819-b5267299d1b8"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_941ec447-a080-4910-aa01-a962bd3fb945\", \"papel-moeda_st_mt.tsv\", 4859)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"papel-moeda_st_mt.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R-4HnehTMtM"
   },
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvzKEagyclEh"
   },
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGONcUFshk97",
    "outputId": "b69645c2-23e2-465e-a3ba-1fb0c208ca04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 44.15\n",
      "TER: 49.65\n",
      "chrF: 65.09\n"
     ]
    }
   ],
   "source": [
    "# References and hypotheses should be lists of strings (sentences)\n",
    "references = [ht_sentences]  # reference: HT\n",
    "hypothesis = mt_sentences    # hypothesis: MT\n",
    "\n",
    "# BLEU\n",
    "bleu = sacrebleu.corpus_bleu(hypothesis, references)\n",
    "print(\"BLEU:\", round(bleu.score, 2))\n",
    "\n",
    "# TER\n",
    "ter = sacrebleu.corpus_ter(hypothesis, references)\n",
    "print(\"TER:\", round(ter.score, 2))\n",
    "\n",
    "# chrF\n",
    "chrf = sacrebleu.corpus_chrf(hypothesis, references)\n",
    "print(\"chrF:\", round(chrf.score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500,
     "referenced_widgets": [
      "f8eb5dafc40d4eea9f4750e1474bc48f",
      "037fe813627b4164a96083e59118ad13",
      "e91970ecec1e4e89ac3cbd70f4d70f86",
      "0e143bd9a1ec43bb8ab19f61c085b7eb",
      "c36b6a4c69f94ceba872d9cfc2e697d7",
      "d65d2eb53dc74da8953097e63f599b38",
      "b0446c97ff3c4f348499d642e29f127d",
      "233f532e88104119a513800ac1d61536",
      "a93f64d843334a168ea0eb3c7f00ecce",
      "b046ddf03f0d42f09e4415c305f17def",
      "a6f22e453bb849fc904cf7b7a49034aa",
      "2db0a70d61584d96bc43dd2d695ae65b",
      "75434a5117804fbaa6061a173628d3bb",
      "a496f5718ae24334839a25839f7c3edd",
      "51936861c9e84945843de69196bfd3cc",
      "b8d1d5137c1949a7968f39a4a55a8db3",
      "abb5e99f357e41e2b4d2ce90ff8c6c8b",
      "c41b94f07f944c98940faa6875cb843d",
      "9d1c8e9391a7464ca657d82982faefa7",
      "8ab659e79d1e458885c09fb8918e9fb7",
      "863b8f54adcb42ef9db497729362c9d3",
      "2c0e8e1bc3d04e08b84d741f0e8c2e68",
      "f009f6449371405f8c078ecb5dab8bce",
      "bad8d3d9dfc74f05b1dec1303ba4f7bb",
      "3c3c2227f5104da9b043ef5c8a397e43",
      "1a823346c5c24b1e8d43862b2dc5f1b8",
      "9db4cb1e6b804de981c09c99b0e0f3b3",
      "c2fba79a8a7f4448aa492d5faafbb677",
      "b551ddfdebed44b9882ee27e0985ef63",
      "a0a6294764714e3f885dbad11a521680",
      "a93dcdc44d844c778020be02b8cee9e1",
      "a1acde45b77945159cd7d8debe360964",
      "5b86f5ba8fc14dffbeed9019732bee6b",
      "9f6f62461d35476098b23cc2edb7f680",
      "9ee39d03d70348d892cd73c5e8890f07",
      "3e251578c2ea447d8401097aac83811c",
      "7f9ec5b616004da8a676ada2d5bdaee4",
      "ddf4a4c1a4074422bcd7b01890bd4472",
      "a71909240c5c47528af3089e87bcd9cd",
      "6f22c54c59dd40f88b9da2a843bf4ca3",
      "ee4481e2ebd544dea15db37c7e93f7e8",
      "f024345318fa4fbbad9f104594f55dd1",
      "abee2dd531ec4beb8dcb14640c5a5617",
      "5d8c2c6723034254978a64222230c509",
      "d4e5313306a5488f96eecbd5e7b3ba3c",
      "5c63a6856e26421d95d007686d91a353",
      "92fcc85c44d84dc49ed762ecf3ec6f9d",
      "225b20c457464bbfa2cc4e8afc7c8e0b",
      "fd0baf75ceb54789b76f69ef78baee7b",
      "f6910eb584d042ebbbec7632a7d5fb46",
      "d4947696de944e9990b7052f65178b8f",
      "07ab4b7e90794e73885b8597e6d5ffc4",
      "5ea2c39f3f0b46be9093b29cd8b29036",
      "f578450c561a4c759681e7358894f1f0",
      "0e533a3cf5394ad2a2084c51db45f91d",
      "e6ff2bddff49486e94e7bcf8919dda99",
      "ce331f6b776d496b958a28a2e3032194",
      "ea5a8c44238d45a6953ec8abf0fb4347",
      "3d22b07c118d4d9eaf73c5a8cd7153fe",
      "4386aa0a95a04d689bc909299bfb5fde",
      "9c3f6327b33541d9a180b2ac0b3d6da1",
      "25e053326b2d48a1b3bef8334044d673",
      "e4def44d68bf4acebb115f8a5a1acf91",
      "a40ac74c64384ddfadd893ea882a9029",
      "09060b3949574df5acbbbf07b945df9f",
      "35beb905c8094f91b62f7b411672060a",
      "231d13bf9eb04e898d0e885d67b5aed5",
      "7c28252628f04bec86ff0fd564af9121",
      "4f1bc227f7844b0ea953763df32d6e74",
      "22e4465fb67e434d9de370f69d86e3d3",
      "02a04a2eec934d5fab590400701ad8f0",
      "4b98fc5def8d439d9223994cc825fc35",
      "ff7c9535d7e54a199c0da405d42d9184",
      "7f5e2536f3504e6187319c768514246b",
      "72d3e7b05c61467994f0a21aa2d67ff5",
      "2dab9003366c4130961ec6ed6e55ab04",
      "ffdd276fadaf41278331d45311c735e4",
      "4ab9fc68b64f47c79e885c0550acdc03",
      "9c94dd8e6efd4f0ca04b51aa0f19ac2f",
      "d493617168b94b648780473ff4965498",
      "5bcab6b72aa344ee9d3ea3135830631d",
      "d234003677d24ad298120f76286b9dbe",
      "08fa3a5768bf402793eb213bc97f29c3",
      "7a93aff9e45e400ba7ca9422f528c81f",
      "111436ede4aa48a688b53b7e3642ae06",
      "2e135b3fa1e6440b86c29d6b4693f3f4",
      "e2f77e297de54d64b23c256a2b3e0e0f",
      "7bf88b1b1cfb4aff9d5d125513b98942",
      "b9feb0d4ffda48d6ac7d20c0a2015acb",
      "ea6156ccad1640b6a532ccc70e03af75",
      "b108f8fedb12407aa5ffd55f7389bd0c",
      "ce3f7892f22b46ada6751cd0d5e931c7",
      "8a7a677092514e469e060fc586a1f977",
      "918265e14ace4fed920ba648d5585795",
      "9b98c20da3414d238fcbfe40cffdf1e2",
      "3cc55d06fa554b4482706cc6e3feceb4",
      "230e6664916e416da1d305c70a990619",
      "3d190729759147f39a9aec4769698a9f",
      "0458d5d5da2f483ba28d803f27253974",
      "26e9af6467de40d9a5498411b2e0f1e2",
      "370f09ed96284c198bf30c185df5a5f1",
      "015dbe299a2e4c4a9a8c2f374cf98e01",
      "ac2a41e27cbb4c488b83458b16183a08",
      "778cb901303846c9ab6a72671170463d",
      "4fb7b2c60790421ca953e99eb887d572",
      "0cac1337f5bf4f0eb7e7b1b46c347bbd",
      "ebef5b6ce9ec4591aca533e865129d8a",
      "35f1697a5c584e7297f7478b92eb2d71",
      "530fb3b7bbc64ec1b35d82b6468dc677",
      "0891d702128e447a95de2fc00eea06c0"
     ]
    },
    "collapsed": true,
    "id": "NFhKikraYAOQ",
    "outputId": "9c04fb82-1930-4a8a-fd7a-cb260d0a295e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8eb5dafc40d4eea9f4750e1474bc48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db0a70d61584d96bc43dd2d695ae65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f009f6449371405f8c078ecb5dab8bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6f62461d35476098b23cc2edb7f680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e5313306a5488f96eecbd5e7b3ba3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ff2bddff49486e94e7bcf8919dda99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt20-comet-da/snapshots/87819f4d6d4f17e0d1752cc9e0ccfa2064997219/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231d13bf9eb04e898d0e885d67b5aed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab9fc68b64f47c79e885c0550acdc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9feb0d4ffda48d6ac7d20c0a2015acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e9af6467de40d9a5498411b2e0f1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "# Load pretrained COMET model (you can also try 'Unbabel/wmt22-comet-da')\n",
    "wmt20_model_path = download_model(\"Unbabel/wmt20-comet-da\")\n",
    "wmt20_model = load_from_checkpoint(wmt20_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apOMo2oHiiBW",
    "outputId": "44090461-99b9-4643-9ebb-19f54edf9619"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:27<00:00,  9.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMET Score: 0.8434\n"
     ]
    }
   ],
   "source": [
    "# Input format: list of dicts with src, mt, and ref\n",
    "data = [{\"src\": st_sentences[i], \"mt\": mt_sentences[i], \"ref\": ht_sentences[i]} for i in range(len(mt_sentences))]\n",
    "\n",
    "# Predict\n",
    "wmt20_model_output = wmt20_model.predict(data, batch_size=8, gpus=1)\n",
    "print(\"COMET Score:\", round(wmt20_model_output.system_score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSc92jJ_lT7t"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace this with your actual Hugging Face token\n",
    "login(token=\"HF-TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343,
     "referenced_widgets": [
      "ec8e3fd703694a14a19141b06d3af91f",
      "52d4e1005ce44729926d45443421362d",
      "682f3f15cb634c82b90f2c5af907ddd2",
      "b58760e883a9428d9967639b3de7ff71",
      "05435019845f480585c7722af59b43fc",
      "af46dba7ea1941b49123909d3b655fce",
      "964074996c4b41628cbd34e53e275e87",
      "6a87e048e18c4eb48982c8dcae70ec05",
      "0ca38d799819470b9b689920f6cefe2f",
      "0c160388390042fb82d8afeffa63cf41",
      "857b5c04a8d24664bb4301b9b28634ce",
      "26d587a329b346e9ba60f7ed733a6c03",
      "556c73623c1641d98bac314785497c0e",
      "f148e2f806314495a686c19575c776ff",
      "04f7edcd7b5e4ca5bc2db2b8796b7855",
      "80a661ba02574e08b5afd869dc6c0ebf",
      "2de5373ad18e47aeae019e685aa2b9ee",
      "65c7c6381593479daa373dfdeb437fed",
      "8ef6a4b7d24b4fd193d536eba8ab9dc8",
      "cfdd19d670944e9f8ce6b1f79781e000",
      "f0c36b9f0cdf4d389f5aa173e7723d1d",
      "784993ce4254453fbc369bf170bd2c05",
      "d1ca8535c09b40a7a3b17ddea546e2af",
      "cf54748f5a28424cb5d58808b786d1e3",
      "bad139eb459844eaa5460f5e8c59abf4",
      "3128456e90634126a6e91553cfd3b18f",
      "453c804026364ecdbcea237de8f77a7b",
      "099a088cecef420a8a398b1e307d5d83",
      "13d673183ca545cdb7ae96b03df24b2c",
      "091c53754da6425a9a0b494452c738de",
      "b3573973f1e34c9286829e241305f411",
      "9c2f6de26f4d4653aed66ed5c108e470",
      "e223cb0ff5344f06a84fff52b4a1cd5d",
      "2e69578c09444417bb8bf53c84303146",
      "0c04c3f7633e4346888a0e80d1a37f9e",
      "272a5d3b5c5a4a4d835b1ea27e7d9aff",
      "94e2f668a3de4d23a2f53fdf6dae1862",
      "bcf7d951344948ea9478846d2deb2328",
      "9d39ff88a01242a780f67f1be32e53c0",
      "cc7e5b8dbb66433f8fe8da8677b4e894",
      "f14e7b3872a44d99aa692c2aafa95fc9",
      "483aac5da598455eade4591ab9b4bef6",
      "9dc6940d05214ae6ae4b914ba63be736",
      "c39eaac3e68d40b296ef4ed56c70950a",
      "3f69545523b24f999f2fcefaccb0d645",
      "95d68c90bbe24527afc219ca923c4d3e",
      "566a5ebe6a1944f593ec5e3312aea7c3",
      "2b0d3078725e4eccaa6eae567762eb50",
      "c5f37eb11214424082d6b5bddc6963b4",
      "8916fbbba23f4c908578ec705023c12c",
      "2f0b6a5e4ba24e9fa13da6b438aea590",
      "e58f24d7fd474f179bd350a937a93b34",
      "123ecff027f94c60afa7e9c63d59f9fe",
      "181050c4c8134c2e81a4306d7a8d3ece",
      "9a43124993a743fea5d2129ee65f0ad9",
      "2993d616a72148519fb12aef288c459d",
      "907196579e3d47fdb8c28f39ebe0376d",
      "25a4182345be48b7ac2077534d449375",
      "4923e3a45edc497f8d770a68072d41d0",
      "69a456f124c0436b8f9ea390a720f599",
      "f4b15eccaf0544f3847b716535a57b6f",
      "7fb058fba38d47219b99724b43762f9c",
      "d70fb587b67e49f5b6a9c398ffe9e169",
      "ed803eca940c42938661e3dce5fa4d14",
      "57bff35b55a640cf8202cb1d8e0d38f9",
      "1b0840fa96da4c2f8fdffcad5bbbc20d",
      "f8c05ab07e7d4d909d5e3ebc73756b46",
      "7f897c12dc3a441f98a0cb1c2495c71e",
      "f85854e89b5342289c293a3372aaa382",
      "c5f1c73cdc6a4bdf9df7f0698dadde84",
      "4bcee2c1cf174f118d997ad01a7cadf0",
      "6958057bc38443f681aa87c6530387ea",
      "2f8a3b70cfaf40a9a422ce52db52e916",
      "f75dc61528e14d96b18960139c4d2088",
      "b4bdf8e0cfeb4d71b783b7e672a3a535",
      "8f25e0e4bcf94eaeba192216aa55f416",
      "82d47b5491e247b5a248310cab126446",
      "4e6b9b9ef8c54ec187e437d74e27eab8",
      "3f4c2df8563944519629968264f6095f",
      "3cef1c65a1a3426c86f0830679d3b5ce",
      "f827e7a18a4a4661bf0360bee4aff383",
      "fd1749f9c9ec4beebf7fae48597101a9",
      "5a750e8af35b4afb9308d16209050a48",
      "fd62d8aa33824c6a808a6b630c631104",
      "c317febd9a9d415ebecd0432c72cab8d",
      "1616b39cc0f24c6c8a57651726a04c9b",
      "097a97602755413d8b0981c937995760",
      "9b573dd3745d40ff9aed0ce0a9779935",
      "40842e338665443c9964a90ce40411d1",
      "13859f893c1d46c2b3e39c0147380b2a",
      "6c6057a8129a4b73bc84b981d1ab7e35",
      "6aa221afcb094a87a281b8450350710c",
      "562d03e57e554521bfb25f79d9d1817b",
      "d657ed07c3304f9e9375d3d7935cc48a",
      "508297e4c2c14a769bf9f9921e740cd3",
      "df497513eb844d3791f93d9087016aaa",
      "d31e0ddbc7c1459db1bcc3dd7c32b203",
      "810729259b2f42fcb03d813cbb54b55a",
      "b0b42bc2174a41fcbeda5441ec7bfd89"
     ]
    },
    "collapsed": true,
    "id": "-dcr3LMGYaa5",
    "outputId": "4f32bd23-5c71-4673-b463-559fc679e55e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8e3fd703694a14a19141b06d3af91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d587a329b346e9ba60f7ed733a6c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ca8535c09b40a7a3b17ddea546e2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e69578c09444417bb8bf53c84303146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f69545523b24f999f2fcefaccb0d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2993d616a72148519fb12aef288c459d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/huggingface/hub/models--Unbabel--wmt22-cometkiwi-da/snapshots/1ad785194e391eebc6c53e2d0776cada8f83179a/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c05ab07e7d4d909d5e3ebc73756b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b9b9ef8c54ec187e437d74e27eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40842e338665443c9964a90ce40411d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/513 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wmt22_model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "wmt22_model = load_from_checkpoint(wmt22_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCYdnnAMjLkY",
    "outputId": "e1de7d66-5c4c-453a-92b6-6cbc6a1c0f2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:16<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XCOMET Score for MT: 0.8248\n"
     ]
    }
   ],
   "source": [
    "data = [{\"src\": st_sentences[i], \"mt\": mt_sentences[i]} for i in range(len(mt_sentences))]  # no reference\n",
    "wmt22_model_output_mt = wmt22_model.predict(data, batch_size=8, gpus=1)\n",
    "print(\"XCOMET Score for MT:\", round(wmt22_model_output_mt.system_score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cf6bMBmplwAq",
    "outputId": "7977c7cf-bc9b-49c3-eab0-77103134ea74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:15<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XCOMET Score for HT: 0.8144\n"
     ]
    }
   ],
   "source": [
    "data = [{\"src\": st_sentences[i], \"mt\": ht_sentences[i]} for i in range(len(ht_sentences))]  # no reference\n",
    "wmt22_model_output_ht = wmt22_model.predict(data, batch_size=8, gpus=1)\n",
    "print(\"XCOMET Score for HT:\", round(wmt22_model_output_ht.system_score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TcBOZWhQY2F"
   },
   "outputs": [],
   "source": [
    "bleu_score = round(bleu.score, 2)\n",
    "ter_score = round(ter.score, 2)\n",
    "chrf_score = round(chrf.score, 2)\n",
    "comet_score = round(wmt20_model_output.system_score, 3)\n",
    "xcomet_mt_score = round(wmt22_model_output_mt.system_score, 3)\n",
    "xcomet_ht_score = round(wmt22_model_output_ht.system_score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwUYwa5OQhj3"
   },
   "outputs": [],
   "source": [
    "def print_metrics_latex_table(bleu, ter, chrf, comet, xcomet_mt, xcomet_ht):\n",
    "    print(\"\\\\begin{tabular}{lcc}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\"Metric & MT & HT \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    print(\"BLEU & {:.2f} & -- \\\\\\\\\".format(bleu))\n",
    "    print(\"TER & {:.2f} & -- \\\\\\\\\".format(ter))\n",
    "    print(\"chrF & {:.2f} & -- \\\\\\\\\".format(chrf))\n",
    "    print(\"COMET & {:.3f} & -- \\\\\\\\\".format(comet))\n",
    "    print(\"XCOMET & {:.3f} & {:.3f} \\\\\\\\\".format(xcomet_mt, xcomet_ht))\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgDL68DYQlLK",
    "outputId": "a8932f6b-ad79-4007-d943-b11bb8753078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcc}\n",
      "\\toprule\n",
      "Metric & MT & HT \\\\\n",
      "\\midrule\n",
      "BLEU & 44.15 & -- \\\\\n",
      "TER & 49.65 & -- \\\\\n",
      "chrF & 65.09 & -- \\\\\n",
      "COMET & 0.843 & -- \\\\\n",
      "XCOMET & 0.825 & 0.814 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print_metrics_latex_table(bleu_score, ter_score, chrf_score, comet_score, xcomet_mt_score, xcomet_ht_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
